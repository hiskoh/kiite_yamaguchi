import streamlit as st
import json, random, io, re, boto3
import numpy as np
from datetime import datetime
from openai import OpenAI
from oauth2client.service_account import ServiceAccountCredentials
import gspread

st.set_page_config(page_title="ãã„ã¦ãƒŸãƒ©ã‚¤ï½œå¸‚é•·ç™ºè¨€AIåˆ†æ", layout="wide", page_icon="ğŸ›ï¸")

def render_items(items):
    if not items:
        st.info("è©²å½“ãªã—")
        return

    for m in items:
        source_file = m.get("source_file", "").replace(".txt", "")
        date = m.get("date")
        topic = m.get("topic", "æœªåˆ†é¡")
        header = m.get("title") or m.get("snippet") or source_file or "é–¢é€£ç™ºè¨€"
        source = f"""<span style="font-size:0.9em; color:gray;">{source_file}</span>"""

        with st.expander(f"{topic}" if date else header, expanded=False):
            st.markdown(m.get("text", "") or "_(textç©º)_")
            st.markdown(source, unsafe_allow_html=True)

        
# ====== â–¼ åˆæœŸå€¤è¨­å®š ========================================================

#æ¤œç´¢çµæœã®è¨­å®š
TOP_N_RETURN       = 10         # æœ€çµ‚çš„ã«è¿”ã™ä»¶æ•°
SIM_THRESHOLD      = 0.1        # é¡ä¼¼åº¦ã®ã—ãã„å€¤ï¼ˆ0.0ï½1.0ï¼‰
TOPK_CANDIDATES    = 30         # S3Vectorsã‹ã‚‰ä¸€æ—¦å–ã‚Šå¯„ã›ã‚‹å€™è£œæ•°ï¼ˆå¤šã‚ã«ï¼‰

#ChatGPTã®è¨­å®š
GPT_MODEL = "gpt-4.1-mini"
GPT_TEMPERATURE = 0.1
EMBED_MODEL         = "text-embedding-3-small"  

#AWSã®è¨­å®š
AWS_REGION          = "us-west-2"
OUTPUT_PREFIX       = "mayor_chunk_jsonl/" 
SCORE_THRESHOLD     = 0.0
AWS_ACCESS_KEY_S    = st.secrets["AWS-KEY"]["AWS_ACCESS_KEY"]
AWS_SECRET_KEY_S    = st.secrets["AWS-KEY"]["AWS_SECRET_KEY"]     
DATA_BUCKET_NAME    = st.secrets["AWS-KEY"]["DATA_BUCKET_NAME"]        
S3_INDEX_ARN_MAYOR        = st.secrets["AWS-KEY"]["VECTOR_INDEX_ARN_MAYOR"]
# ====== â–² åˆæœŸå€¤è¨­å®š ========================================================

for key in ["agreed", "query", "send_now", "last_answer", "last_matches", "is_generating", "input", "input_value", "clarified", "clarify_active", "suggestions_sampled"]:
    if key not in st.session_state:
        if key in ["query", "last_answer", "input", "input_value"]:
            st.session_state[key] = ""
        elif key == "suggestions_sampled":
            st.session_state[key] = []
        else:
            st.session_state[key] = False

if not st.session_state.agreed:
    st.title("ğŸ›ï¸ãã„ã¦ãƒŸãƒ©ã‚¤ï½œå¸‚é•·ç™ºè¨€AIåˆ†æ")
    st.markdown("""
    ### ã”åˆ©ç”¨ã«ã‚ãŸã£ã¦ã®ã”æ¡ˆå†…

    - ã“ã®ãƒãƒ£ãƒƒãƒˆã§ã¯ã€å±±å£å¸‚é•·ã®éå»ã®ç™ºè¨€ï¼ˆå®šä¾‹ä¼šè¦‹ã€è­°ä¼šåˆæ—¥ã«è¡Œã‚ã‚Œã‚‹å¸‚æ”¿æ¦‚æ³å ±å‘Šï¼‰ã‚’ã‚‚ã¨ã«ã€å¸‚é•·ã®è¦‹è§£ã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ 
    - ãƒãƒ£ãƒƒãƒˆå†…å®¹ã¯è¨˜éŒ²ã•ã‚Œã¾ã™ã€‚å†…å®¹ã®è¨˜éŒ²ã«åŒæ„ã•ã‚ŒãŸæ–¹ã®ã¿ã€ãƒãƒ£ãƒƒãƒˆã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚ 
    - **å€‹äººæƒ…å ±ï¼ˆæ°åãƒ»ä½æ‰€ãƒ»é€£çµ¡å…ˆãªã©ï¼‰ã®å…¥åŠ›ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚**  
    """)
    st.warning("ã“ã®ãƒãƒ£ãƒƒãƒˆã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®å†…å®¹ã«åŒæ„ã„ãŸã ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
    if st.button("âœ… åŒæ„ã—ã¦ãƒãƒ£ãƒƒãƒˆã‚’ã¯ã˜ã‚ã‚‹"):
        st.session_state.agreed = True
        st.rerun()
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def get_gspread_client():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(st.secrets["gsheets_service_account"], scope)
    return gspread.authorize(creds)

def log_to_gsheet(question, answer):
    client_gs = get_gspread_client()
    sheet = client_gs.open_by_key(st.secrets["kiite-mirai"]["GOOGLE_MIRAI_LOG_SHEET_ID"]).worksheet("logs")
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    sheet.append_row([now, question, answer])

def load_prompt(name):
    with open(f"prompts/{name}", "r", encoding="utf-8") as f:
        return f.read()

def clarify_query(user_query):
    clarify_prompt = load_prompt("mirai_clarify_prompt.txt")
    messages = [
        {"role": "system", "content": clarify_prompt},
        {"role": "user", "content": f"ã€è³ªå•ã€‘{user_query}"}
    ]
    try:
        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=messages,
            temperature=GPT_TEMPERATURE
        )
        content = response.choices[0].message.content.strip()
        return json.loads(content)
    except Exception as e:
        st.error(f"Clarifyã‚¨ãƒ©ãƒ¼")
        return {"ambiguous": False, "reason": "", "rewritten_query": ""}

# ========= â–¼ ã“ã“ã‹ã‚‰S3 Vectorsã§ã®æ¤œç´¢ã‚’å®Ÿè£… ===============================

def _to_similarity(distance: float) -> float:
    """distanceï¼ˆcosineæƒ³å®šï¼‰â†’ é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ 1 - distance"""
    try:
        d = float(distance)
    except Exception:
        return 0.0
    return max(0.0, min(1.0, 1.0 - d))

def _fetch_original_chunk_for_search(s3_client, source_file: str, chunk_id: str) -> tuple[dict | None, str]:
    """
    å…ƒjsonlã®è©²å½“chunk(dict) ã¨ã€å‚ç…§ã—ãŸS3ã‚­ãƒ¼(æ–‡å­—åˆ—)ã‚’è¿”ã™ã€‚
    è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã¯ (None, key) ã‚’è¿”ã™ã€‚
    """
    base = source_file
    key  = f"{OUTPUT_PREFIX}{base}.jsonl"
    try:
        body = s3_client.get_object(Bucket=DATA_BUCKET_NAME, Key=key)["Body"].read().decode("utf-8")
    except Exception:
        return None, key

    for line in body.splitlines():
        if not line.strip():
            continue
        try:
            obj = json.loads(line)
        except Exception:
            continue
        if obj.get("chunk_id") == chunk_id:
            return obj, key
    return None, key

def _query_s3vectors(query_text: str, top_k_: int, score_threshold: float):
    # OpenAIåŸ‹ã‚è¾¼ã¿
    oai = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    emb = oai.embeddings.create(model=EMBED_MODEL, input=query_text)
    qvec = [float(x) for x in emb.data[0].embedding]

    # S3 / S3Vectors ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    s3_client = boto3.client(
        "s3",
        aws_access_key_id=AWS_ACCESS_KEY_S,
        aws_secret_access_key=AWS_SECRET_KEY_S,
        region_name=AWS_REGION,
    )
    s3v_client = boto3.client(
        "s3vectors",
        aws_access_key_id=AWS_ACCESS_KEY_S,
        aws_secret_access_key=AWS_SECRET_KEY_S,
        region_name=AWS_REGION,
    )

    # å¤šã‚ã«å–å¾—
    res = s3v_client.query_vectors(
        indexArn=S3_INDEX_ARN_MAYOR,
        queryVector={"float32": qvec},
        topK=max(TOPK_CANDIDATES, top_k_),
        returnMetadata=True,
        returnDistance=True,
    )
    matches = res.get("vectors", []) or []

    out = []
    for m in matches:
        key       = m.get("key") or m.get("id")
        distance  = float(m.get("distance", 0.0))
        score     = _to_similarity(distance)
        if score < score_threshold:
            continue

        md        = m.get("metadata") or {}
        source    = md.get("source_file")
        chunk_id  = md.get("chunk_id") or key

        original, jsonl_key = _fetch_original_chunk_for_search(s3_client, source, chunk_id)

        out.append({
            "score": score,
            "distance": distance,
            "key": key,
            "source_file": source,
            "chunk_id": chunk_id,
            "original": original
        })

    out.sort(key=lambda x: x["score"], reverse=True)
    return out

# ç™ºè¨€éŒ²ã‚’æ¤œç´¢
def search_s3vector_and_respond(query):
    try:
        hits = _query_s3vectors(
            query_text=query,
            top_k_=TOP_N_RETURN,            
            score_threshold=SIM_THRESHOLD   
        )
    except Exception as e:
        return {"matches": [], "summary": f"ğŸ” æ¤œç´¢ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"}

    if not hits:
        return {"matches": [], "summary": "ğŸ” é¡ä¼¼åº¦ã®é«˜ã„ç™ºè¨€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"}

    # âœ… é¡ä¼¼åº¦ã§é™é † â†’ ä¸Šä½10ä»¶ã ã‘
    top_hits = hits[:TOP_N_RETURN]

    # è¿”å´å½¢ã®æ•´å½¢ï¼ˆUIã«ã¯ã€Œã‚¹ã‚³ã‚¢ï¼é¡ä¼¼åº¦ã€ã‚’å‡ºã™ã‚ˆã†å¤‰æ›´ï¼‰
    top_matches = []
    for h in top_hits:
        o = h.get("original") or {}
        top_matches.append({
            "text": o.get("text") or "",
            "topic": o.get("topic") or "æœªåˆ†é¡",
            "source_file": h.get("source_file") or o.get("source_file") or "",
            "date": o.get("date"),
            "type": o.get("type"),
            "score": float(h.get("score", 0.0)),  # â† é¡ä¼¼åº¦ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
            "chunk_id": h.get("chunk_id"),
            "source_index": "s3vectors",
        })

    # ğŸ§  ä¸Šä½10ä»¶ã®æœ¬æ–‡ã‚’ã¾ã¨ã‚ã¦è¦ç´„
    try:
        combined_text = "\n\n".join(m["text"] for m in top_matches if m.get("text"))

        base_prompt = load_prompt("mirai_summary.txt")
        guard = f"""
        ---
        ã€è¿½åŠ åˆ¶ç´„ã€‘
        - ä»¥é™ã®è¦ç´„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€Œ{query}ã€ã«ç›´æ¥é–¢é€£ã™ã‚‹æƒ…å ±ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¦ãã ã•ã„ã€‚
        - é–¢é€£ã—ãªã„å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚
        """
        summary_prompt = base_prompt + "\n" + guard
        
        messages = [
            {"role": "system", "content": summary_prompt},
            {"role": "user", "content": combined_text if combined_text else "(è©²å½“ã™ã‚‹æ–‡è„ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ)"},
        ]
        resp = client.chat.completions.create(model=GPT_MODEL, messages=messages, temperature=GPT_TEMPERATURE)
        summary = resp.choices[0].message.content.strip()
    except Exception as e:
        summary = f"âš ï¸ å…¨ä½“ã‚µãƒãƒªç”Ÿæˆå¤±æ•—"

    return {"matches": top_matches, "summary": summary}

    # æ—¥ä»˜ã®é™é †ã«ä¸¦ã¹ã‚‹:
    # items = sorted(items, key=lambda x: str(x.get("date", "")), reverse=True)

    for m in items:
        source_file = m.get("source_file", "").replace(".txt", "")
        date = m.get("date")
        topic = m.get("topic", "æœªåˆ†é¡")
        # expander ã®è¦‹å‡ºã—ï¼ˆã‚¿ã‚¤ãƒˆãƒ«å„ªå…ˆâ†’ã‚¹ãƒ‹ãƒšãƒƒãƒˆâ†’source_fileï¼‰
        header = m.get("title") or m.get("snippet") or source_file or "é–¢é€£ç™ºè¨€"

        # å‡ºå…¸æƒ…å ±
        source = f"""<span style="font-size:0.9em; color:gray;">{source_file}</span>"""

        # ã‚¿ãƒ–å´ã§ type ã‚’ç¢ºå®šæ¸ˆã¿ãªã®ã§ã€expander è¦‹å‡ºã—ã¯å†…å®¹ã«é›†ä¸­
        with st.expander(f"{topic}" if date else header, expanded=False):
            st.markdown(m.get("text", ""))
            st.markdown(source, unsafe_allow_html=True)

st.title("ğŸ›ï¸ ãã„ã¦ãƒŸãƒ©ã‚¤ï½œå¸‚é•·ç™ºè¨€AIåˆ†æ")

# --- ãƒãƒ£ãƒƒãƒˆæ¬„ï¼ˆé€ä¿¡ãƒœã‚¿ãƒ³ãªã—ãƒ»Enteré€ä¿¡ï¼‰ ---
st.markdown("---\n\n#### ğŸ’¬ è³ªå•ã—ã¦ã¿ã‚ˆã†")
st.text_input(
    label="",
    key="input",
    value=st.session_state.input_value,
    placeholder="ä¾‹ï¼šã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰è¦³å…‰ã«å¯¾ã™ã‚‹å–ã‚Šçµ„ã¿ã¯ï¼Ÿ",
    on_change=lambda: st.session_state.update(send_now=True)
)

# --- ã‚µã‚¸ã‚§ã‚¹ãƒˆ ---
if not st.session_state.get("clarify_active", False):
    suggestions_master = [
        "é˜²ç½ã«é–¢ã™ã‚‹å¸‚é•·ã®ç™ºè¨€ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "å­è‚²ã¦æ”¯æ´ã®æ–¹é‡ã«ã¤ã„ã¦æ•™ãˆã¦",
        "åœ°åŸŸæ´»æ€§åŒ–ã«å‘ã‘ãŸå–ã‚Šçµ„ã¿ã¯ï¼Ÿ"
    ]
    if not st.session_state.suggestions_sampled:
        st.session_state.suggestions_sampled = random.sample(suggestions_master, k=3)

    cols = st.columns(3)
    for i, s in enumerate(st.session_state.suggestions_sampled):
        if cols[i].button(s, key=f"sugg_{s}"):
            st.session_state.input_value = s
            st.session_state.query = s
            st.session_state.send_now = True
            st.session_state.is_generating = True
            st.session_state.clarify_active = False
            with st.spinner(f"â³ ã€Œ{s}ã€ã«å›ç­”ä¸­... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„"):
                results = search_s3vector_and_respond(s)
                st.session_state.last_answer = results["summary"]
                st.session_state.last_matches = results["matches"]

                # ãƒ­ã‚°è¨˜éŒ²
                try:
                    log_to_gsheet(s, results["summary"])
                except Exception as e:
                    st.warning(f"âš ï¸ ãƒ­ã‚°è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ")

            st.session_state.is_generating = False
            st.rerun()

# Clarifyãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç¢ºèª
if st.session_state.input and not st.session_state.get("clarified", False):
    clarify_result = clarify_query(st.session_state.input)

    if clarify_result["ambiguous"] and clarify_result["rewritten_query"]:
        st.session_state.clarify_active = True
        st.info(f"ğŸ‘‡ ã‚ˆã‚Šæ­£ç¢ºãªæ¤œç´¢ã®ãŸã‚ã€Œ{clarify_result['reason']}ã€ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ä¾‹ãˆã°ã€ä»¥ä¸‹ã®è³ªå•ã«ç½®ãæ›ãˆã‚‹ã®ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿ\n\n**â†’ {clarify_result['rewritten_query']}**")

        col1, col2 = st.columns(2)
        if col1.button("ğŸ” ç½®ãæ›ãˆã¦æ¤œç´¢"):
            st.session_state.input_value = clarify_result["rewritten_query"]
            st.session_state.clarified = True
            st.session_state.clarify_active = False
            st.session_state.send_now = True
            st.rerun()
        if col2.button("ğŸ”œ å…¥åŠ›æ–‡ã®ã¾ã¾ã§æ¤œç´¢"):
            st.session_state.clarified = True
            st.session_state.clarify_active = False
            st.session_state.send_now = True
            st.rerun()
        st.stop()

    else:
        # ğŸŸ¨ ã‚ã„ã¾ã„ã§ãªã„ or æ˜ç¢ºãªä¿®æ­£ææ¡ˆãŒãªã„å ´åˆã‚‚ã€Clarifyã¯çµ‚äº†
        st.session_state.clarified = True

# --- é€ä¿¡å‡¦ç†ï¼ˆEnter or ã‚µã‚¸ã‚§ã‚¹ãƒˆé¸æŠæ™‚ï¼‰ ---
if st.session_state.input and st.session_state.send_now:
    st.session_state.send_now = False
    st.session_state.is_generating = True
    with st.spinner(f"â³ ã€Œ{st.session_state.input}ã€ã«å›ç­”ä¸­... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„"):
        results = search_s3vector_and_respond(st.session_state.input)
        st.session_state.last_answer = results["summary"]
        st.session_state.last_matches = results["matches"]

        # ãƒ­ã‚°è¨˜éŒ²
        try:
            log_to_gsheet(st.session_state.input, results["summary"])
        except Exception as e:
            st.warning(f"âš ï¸ ãƒ­ã‚°è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ")

    st.session_state.input_value = ""
    st.session_state.is_generating = False

if st.session_state.is_generating:
    st.info("â³ å›ç­”ä¸­... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„")
elif st.session_state.last_answer:
    st.divider()
    st.caption("å…¥åŠ›ã•ã‚ŒãŸè³ªå•ã«å¯¾ã—ã¦ã€AIãŒé¡ä¼¼åº¦ãŒé«˜ã„ã¨åˆ¤æ–­ã—ãŸä¸Šä½10ä»¶ã®ç™ºè¨€ã‚’ã‚‚ã¨ã«å›ç­”ã—ã¾ã™")
    st.markdown("#### ğŸ’¡ å¸‚é•·ç™ºè¨€ã®ã¾ã¨ã‚")
    st.success(st.session_state.last_answer)  #  ã‚µãƒãƒªæœ¬æ–‡ã®å‡ºåŠ›ä½ç½®
    
    st.subheader("é–¢é€£ç™ºè¨€ã®è©³ç´°")
    

    
    # 1) ã¾ãšåˆ†é¡
    press_items = []    # å®šä¾‹ä¼šè¦‹
    council_items = []  # å¸‚æ”¿æ¦‚æ³å ±å‘Š 

    for m in st.session_state.last_matches:
        source_file_raw = m.get("source_file", "")
        source_file = source_file_raw.replace(".txt", "")
        date = m.get("date")
        topic = m.get("topic", "æœªåˆ†é¡")
        type = "å®šä¾‹ä¼šè¦‹" if "ä¼šè¦‹" in source_file else "è­°ä¼š å¸‚æ”¿æ¦‚æ³å ±å‘Š"

        # å¾Œæ®µã®æç”»ã§ä½¿ã„ã‚„ã™ã„ã‚ˆã†æ•´å½¢ã—ã¦ append
        enriched = {
            **m,
            "type": type,
            "topic": topic,
            "source_file": source_file,
            "date": date,
        }
        (press_items if type == "å®šä¾‹ä¼šè¦‹" else council_items).append(enriched)

    # 2) ã‚¿ãƒ–ã§åˆ†ã‘ã¦è¡¨ç¤º
    tabs = st.tabs([f"å®šä¾‹ä¼šè¦‹ï¼ˆ{len(press_items)}ï¼‰", f"è­°ä¼š å¸‚æ”¿æ¦‚æ³å ±å‘Šï¼ˆ{len(council_items)}ï¼‰"])
    
    with tabs[0]:
        render_items(press_items)
        # ä¸€æ¬¡ã‚½ãƒ¼ã‚¹ã‚’æ˜ç¤º
        st.markdown(
            """
            <div style="
                background-color:#f5f5f5;
                border:1px solid #ddd;
                border-radius:6px;
                padding:0.8em 1em;
                margin-top:0.8em;
                margin-bottom:0.8em;
                ">
                ğŸ”— å…¬å¼æƒ…å ±ã¯ã“ã¡ã‚‰ã‹ã‚‰ã”è¦§ã„ãŸã ã‘ã¾ã™<br>
                ãƒ» <a href="https://www.city.yamaguchi.lg.jp/site/shicho/list68.html" target="_blank">
                    å±±å£å¸‚ å¸‚é•·ã®éƒ¨å±‹ è¨˜è€…ä¼šè¦‹ï¼ˆå¸‚å…¬å¼HPï¼‰
                  </a> <br>
                ãƒ» <a href="https://www.youtube.com/playlist?list=PLSBXr_PDKAbMOBbQdeQslWsrmSr-LyOdl" target="_blank">
                    å¸‚é•·å®šä¾‹è¨˜è€…ä¼šè¦‹ï¼ˆå¸‚å…¬å¼YouTubeï¼‰
                  </a>
            </div>
            """,
            unsafe_allow_html=True,
        )
        
            
    with tabs[1]:
        render_items(council_items)
        st.markdown(
            """
            <div style="
                background-color:#f5f5f5;
                border:1px solid #ddd;
                border-radius:6px;
                padding:0.8em 1em;
                margin-top:0.8em;
                margin-bottom:0.8em;
                ">
                ğŸ”— å…¬å¼æƒ…å ±ã¯ã“ã¡ã‚‰ã‹ã‚‰ã”è¦§ã„ãŸã ã‘ã¾ã™<br>
                ãƒ» <a href="https://www.city.yamaguchi.yamaguchi.dbsr.jp/index.php/" target="_blank">
                    å±±å£å¸‚è­°ä¼š è­°äº‹éŒ²ï¼ˆå…¬å¼HPï¼‰
                  </a>
            </div>
            """,
            unsafe_allow_html=True,
        )

st.divider()
st.caption("""
âš ï¸ å›ç­”ã¯ç”ŸæˆAIã«ã‚ˆã‚‹ã‚‚ã®ã§ã‚ã‚Šã€æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚  
ğŸ™Œ æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å€‹äººã«ã‚ˆã‚Šé‹å–¶ã•ã‚Œã¦ã„ã¾ã™ã€‚ã”æ”¯æ´ã„ãŸã ã‘ã‚‹æ–¹ã¯ãœã²ã“ã¡ã‚‰ã‹ã‚‰ï¼š  
[ğŸ’› codocã§æ”¯æ´ã™ã‚‹](https://codoc.jp/sites/p8cEFlTZQA/entries/MMZnODc1dw)
""")
