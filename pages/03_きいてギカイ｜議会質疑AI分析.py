# -*- coding: utf-8 -*-
import streamlit as st
import json, random, re, boto3
from datetime import datetime
from openai import OpenAI
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from collections import defaultdict

st.set_page_config(page_title="ãã„ã¦ã‚®ã‚«ã‚¤ï½œè­°ä¼šè³ªç–‘AIåˆ†æ", layout="wide", page_icon="ğŸ“œ")

# ====== â–¼ åˆæœŸå€¤è¨­å®š ========================================================
# æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
TOP_N_RETURN       = 10         
SIM_THRESHOLD      = 0.1        
TOPK_CANDIDATES    = 30         

#ChatGPTã®è¨­å®š
GPT_MODEL        = "gpt-4.1-mini"
GPT_TEMPERATURE  = 0.1
EMBED_MODEL      = "text-embedding-3-small"  

#AWSã®è¨­å®š
AWS_REGION       = "us-west-2"
OUTPUT_PREFIX    = "council_chunk_jsonl_ui/"  
#OUTPUT_PREFIX    = "council_chunk_jsonl/"  
AWS_ACCESS_KEY_S = st.secrets["AWS-KEY"]["AWS_ACCESS_KEY"]
AWS_SECRET_KEY_S = st.secrets["AWS-KEY"]["AWS_SECRET_KEY"]
DATA_BUCKET_NAME = st.secrets["AWS-KEY"]["DATA_BUCKET_NAME"]
S3_INDEX_ARN     = st.secrets["AWS-KEY"]["VECTOR_INDEX_ARN_COUNCIL"]
# ====== â–² åˆæœŸå€¤è¨­å®š ========================================================

# ========================= ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– =========================
for key in ["agreed", "query", "send_now", "last_answer", "last_matches", "is_generating",
            "input", "input_value", "suggestions_sampled", "qa_pairs", "clarified", "clarify_active"]:
    if key not in st.session_state:
        if key in ["query", "last_answer", "input", "input_value"]:
            st.session_state[key] = ""
        elif key == "suggestions_sampled":
            st.session_state[key] = []
        elif key in ["last_matches", "qa_pairs"]:
            st.session_state[key] = []
        elif key == "clarify_active":
            st.session_state[key] = False
        else:
            st.session_state[key] = False

# ========================= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========================
def load_prompt(filename: str, default_text: str = "") -> str:
    try:
        with open("prompts/" + filename, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return default_text

def _to_similarity(distance: float) -> float:
    """cosineè·é›¢ â†’ é¡ä¼¼åº¦(1 - distance)"""
    try:
        d = float(distance)
    except Exception:
        return 0.0
    return max(0.0, min(1.0, 1.0 - d))

def _base_from_chunk_id(chunk_id: str) -> str:
    """'xxxx_000' â†’ 'xxxx'"""
    return re.sub(r"_[0-9]{1,3}$", "", chunk_id or "")

# ========================= ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ =========================
client_oai = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def _boto_s3():
    return boto3.client(
        "s3",
        aws_access_key_id=AWS_ACCESS_KEY_S,
        aws_secret_access_key=AWS_SECRET_KEY_S,
        region_name=AWS_REGION,
    )

def _boto_s3vectors():
    return boto3.client(
        "s3vectors",
        aws_access_key_id=AWS_ACCESS_KEY_S,
        aws_secret_access_key=AWS_SECRET_KEY_S,
        region_name=AWS_REGION,
    )

# ========================= JSONLã‚¢ã‚¯ã‚»ã‚¹ï¼ˆS3 Selectãªã—ï¼‰ =========================
_jsonl_cache = {}

def _load_jsonl_lines(s3_client, base_name: str):
    """
    OUTPUT_PREFIX/{base}.jsonl ã‚’å–å¾—ã—ã¦å…¨è¡Œã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã€‚
    """
    key = f"{OUTPUT_PREFIX}{base_name}.jsonl"
    if key in _jsonl_cache:
        return _jsonl_cache[key]

    try:
        body = s3_client.get_object(Bucket=DATA_BUCKET_NAME, Key=key)["Body"].read().decode("utf-8")
    except Exception:
        _jsonl_cache[key] = []
        return _jsonl_cache[key]

    rows: List[Dict[str, Any]] = []
    for line in body.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
            rows.append(obj)
        except Exception:
            continue

    _jsonl_cache[key] = rows
    return rows

def _get_pair_records_from_file(rows, pair_id):
    """
    äº‹å‰ã«èª­ã¿è¾¼ã‚“ã rowsã‹ã‚‰ pair_id ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’è¿”ã™ã€‚Qâ†’Aâ†’Nã®é †ã«æ•´åˆ—ã€‚
    """
    pid_int = int(pair_id)
    pid_str = str(pid_int)
    recs = [r for r in rows if (r.get("pair_id") == pid_int or str(r.get("pair_id")) == pid_str)]
    order = {"Q": 0, "A": 1, "N": 2}
    recs.sort(key=lambda r: order.get(r.get("qa_role"), 9))
    return recs

# ========================= ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆS3 Vectorsï¼‰ =========================
def _query_s3vectors(query_text):
    emb = client_oai.embeddings.create(model=EMBED_MODEL, input=query_text)
    qvec = [float(x) for x in emb.data[0].embedding]

    s3v = _boto_s3vectors()
    res = s3v.query_vectors(
        indexArn=S3_INDEX_ARN,
        queryVector={"float32": qvec},
        topK=TOPK_CANDIDATES,
        returnMetadata=True,
        returnDistance=True,
    )
    matches = res.get("vectors", []) or []

    out = []
    for m in matches:
        distance = float(m.get("distance", 0.0))
        score = max(0.0, min(1.0, 1.0 - distance))
        if score < SIM_THRESHOLD:
            continue

        md = m.get("metadata") or {}
        out.append({
            "score": score,
            "distance": distance,
            "key": m.get("key") or m.get("id"),
            "source_file": md.get("source_file") or md.get("source_id") or md.get("source") or "",
            "chunk_id": md.get("chunk_id") or md.get("chank_id") or (m.get("key") or m.get("id")),
            "pair_id": int(float(md["pair_id"])) if md.get("pair_id") is not None else None,
        })

    out.sort(key=lambda x: x["score"], reverse=True)
    return out

# ========================= Google Sheets ãƒ­ã‚° =========================
def get_gspread_client():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(st.secrets["gsheets_service_account"], scope)
    return gspread.authorize(creds)

def log_to_gsheet(question, answer):
    try:
        client_gs = get_gspread_client()
        sheet = client_gs.open_by_key(st.secrets["kiite-gikai"]["GOOGLE_GIKAI_LOG_SHEET_ID"]).worksheet("logs")
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        sheet.append_row([now, question, answer])
    except Exception as e:
        st.warning(f"âš ï¸ ãƒ­ã‚°è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ")

# ========================= clarifyæ©Ÿèƒ½ =========================
def clarify_query(user_query):
    clarify_prompt = load_prompt("gikai_clarify_prompt.txt")
    messages = [
        {"role": "system", "content": clarify_prompt},
        {"role": "user", "content": f"ã€è³ªå•ã€‘{user_query}"},
    ]
    try:
        response = client_oai.chat.completions.create(
            model=GPT_MODEL,
            messages=messages,
            temperature=GPT_TEMPERATURE
        )
        return json.loads(response.choices[0].message.content.strip())
    except Exception as e:
        st.error(f"Clarifyã‚¨ãƒ©ãƒ¼")
        return {"ambiguous": False, "reason": "", "rewritten_query": ""}

# ========================= æ¤œç´¢ã€œè¦ç´„ æœ¬ä½“ =========================
def search_s3vector_and_respond(query):
    """
    - S3Vectorsã§å€™è£œã‚’å–å¾—ï¼ˆscore=1-distanceã§filterï¼‰
    - (base, pair_id) ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯é›†åˆã‚’ä½œã‚‹
    - å„baseã«å¯¾ã—ã¦ä¸€åº¦ã ã‘ JSONL ã‚’ãƒ­ãƒ¼ãƒ‰ â†’ pair_idä¸€è‡´è¡Œã‚’æŠ½å‡º â†’ Q/A/Nã«æŒ¯ã‚Šåˆ†ã‘
    - Q/AãŒæƒã£ãŸãƒšã‚¢ã‚’è¦ç´„ â†’ å…¨ä½“è¦ç´„
    """
    s3_client = _boto_s3()

    # 1) ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
    try:
        hits = _query_s3vectors(query)
    except Exception as e:
        return {"matches": [], "summary": f"ğŸ” æ¤œç´¢ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", "qa_pairs": []}

    if not hits:
        return {"matches": [], "summary": "ğŸ” é¡ä¼¼åº¦ã®é«˜ã„ç™ºè¨€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", "qa_pairs": []}

    # 2) ç”»é¢ç”¨ã®æ–­ç‰‡ï¼ˆãƒšã‚¢åŒ–ã§ããªã„æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤ºç”¨ï¼‰
    top_hits = hits[:TOP_N_RETURN]
    top_matches_for_ui = []
    for h in top_hits:
        base = _base_from_chunk_id(h.get("chunk_id", ""))
        top_matches_for_ui.append({
            "text": "",  
            "topic": "æœªåˆ†é¡",
            "source_file": h.get("source_file") or f"{base}.txt",
            "date": None,
            "type": None,
            "score": float(h.get("score", 0.0)),
            "chunk_id": h.get("chunk_id"),
            "speaker": "",
            "speaker_role": "",
            "source_id": h.get("source_file") or "",
            "source_index": "s3vectors",
        })

    # 3) (base, pair_id) ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ã—ã¦Q/AæŠ½å‡º
    #    pair_id ãŒ None ã®ãƒ’ãƒƒãƒˆã¯ãƒšã‚¢çµ„æˆå¯¾è±¡ã‹ã‚‰é™¤å¤–ï¼ˆUIæ–­ç‰‡ã®ã¿ï¼‰
    unique_pairs = []
    for h in top_hits:
        pid = h.get("pair_id")
        if pid is None:
            continue
        base = _base_from_chunk_id(h.get("chunk_id", ""))
        key = (base, int(pid))
        if key not in unique_pairs:
            unique_pairs.append(key)
                    
    need = defaultdict(list) 
    for base, pid in unique_pairs:
        need[base].append(pid)

    pair_matches = []
    for base, pid_list in need.items():
        rows = _load_jsonl_lines_select_jsonl(s3_client, base, pid_list)  
        if not rows:
            continue

        # å„ pid ã”ã¨ã« Q/A æŠœãå‡ºã—
        for pid in pid_list:
            recs = [r for r in rows if int(r.get("pair_id", -1)) == int(pid)]
            if not recs:
                continue
            q = [r for r in recs if r.get("qa_role") == "Q"]
            a = [r for r in recs if r.get("qa_role") == "A"]
            if not q and not a:
                continue

            first_cid = ((q and q[0].get("chunk_id")) or (a and a[0].get("chunk_id")) or "")
            meeting_name = first_cid.split("_")[0] if first_cid else "ï¼ˆä¼šè­°åä¸æ˜ï¼‰"

            def _enrich(rec): 
                return {**rec, "source_file": f"{base}.txt"}

            pair_matches.append({
                "pair_id": int(pid),
                "source_file": f"{base}.txt",
                "meeting_name": meeting_name,
                "Q": [_enrich(r) for r in q],
                "A": [_enrich(r) for r in a],
            })


    # 4) ã‚µãƒãƒªç”Ÿæˆ

    guard = f"""
    ---
    ã€è¿½åŠ åˆ¶ç´„ã€‘
    - ä»¥é™ã®è¦ç´„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€Œ{query}ã€ã«ç›´æ¥é–¢é€£ã™ã‚‹æƒ…å ±ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¦ãã ã•ã„ã€‚
    - é–¢é€£ã—ãªã„å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚
    """
            
    gikai_pair_prompt = load_prompt("gikai_pair_summary.txt") + "\n" + guard
    summary_overall_prompt = load_prompt("gikai_summary_overall.txt") + "\n" + guard

    summary_per_pair = []
    for pair in pair_matches:
        q_blocks = []
        for q in pair.get("Q", []):
            role = q.get("speaker_role", "")
            speaker = q.get("speaker", "")
            text = q.get("text", "")
            if text:
                q_blocks.append(f"ã€è³ªå•ã€‘{role} {speaker}ï¼š{text}")

        a_blocks = []
        for a in pair.get("A", []):
            role = a.get("speaker_role", "")
            speaker = a.get("speaker", "")
            text = a.get("text", "")
            if text:
                a_blocks.append(f"ã€ç­”å¼ã€‘{role} {speaker}ï¼š{text}")

        qa_context = "\n\n".join(q_blocks + a_blocks) or "(è©²å½“æ–‡è„ˆãªã—)"

        try:
            resp = client_oai.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": gikai_pair_prompt},
                    {"role": "user", "content": qa_context}
                ],
                temperature=GPT_TEMPERATURE
            )
            summary = resp.choices[0].message.content.strip()
        except Exception as e:
            summary = f"âš ï¸ è¦ç´„å¤±æ•—"

        pair["summary"] = summary
        summary_per_pair.append(summary)

    if summary_per_pair:
        try:
            context = "\n\n".join([f"{i+1}ä»¶ç›®ï¼š{s}" for i, s in enumerate(summary_per_pair)])
            resp = client_oai.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": summary_overall_prompt},
                    {"role": "user", "content": context}
                ],
                temperature=GPT_TEMPERATURE
            )
            summary_overall = resp.choices[0].message.content.strip()
        except Exception as e:
            summary_overall = f"âš ï¸ å…¨ä½“ã‚µãƒãƒªç”Ÿæˆå¤±æ•—"
    else:
        # ãƒšã‚¢ãŒä¸€ã¤ã‚‚çµ„ã‚ãªã‹ã£ãŸå ´åˆã¯æ–­ç‰‡ãƒ™ãƒ¼ã‚¹ã®æ³¨æ„å–šèµ·
        summary_overall = "âš ï¸ Q/Aãƒšã‚¢ã‚’çµ„ã‚ã‚‹ä¸€è‡´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å‚è€ƒã¾ã§ã«é–¢é€£æ–­ç‰‡ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"

    return {
                "matches": top_hits[:TOP_N_RETURN] and top_matches_for_ui or [],
                "summary": summary_overall,
                "qa_pairs": pair_matches
    }


# ========================= S3 Selectã§ã®å¯¾è±¡ãƒ‡ãƒ¼ã‚¿æŠ½å‡º =========================
from collections import defaultdict
def _load_jsonl_lines_select_jsonl(s3_client, base_name: str, pair_ids: list[int]):
    """
    S3 Selectã§ OUTPUT_PREFIX/{base}.jsonlï¼ˆéåœ§ç¸®ï¼‰ã‹ã‚‰
    æŒ‡å®š pair_id ã®è¡Œã ã‘ã‚’æŠ½å‡ºã—ã¦è¿”ã™ã€‚
    å¤±æ•—æ™‚ã¯å¾“æ¥ã®å…¨ä»¶GETâ†’ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    import json
    from botocore.exceptions import ClientError

    key_raw = f"{OUTPUT_PREFIX}{base_name}.jsonl"
    ids = sorted({int(x) for x in pair_ids if x is not None})
    if not ids:
        return []

    # ---- 1) S3 Selectï¼ˆéåœ§ç¸®JSON Linesï¼‰ ----
    try:
        expr_ids = ",".join(str(i) for i in ids)
        resp = s3_client.select_object_content(
            Bucket=DATA_BUCKET_NAME,
            Key=key_raw,
            ExpressionType='SQL',
            Expression=(
                "SELECT s.pair_id, s.qa_role, s.chunk_id, s.text, "
                "       s.speaker, s.speaker_role, s.source_file "
                f"FROM S3Object s WHERE cast(s.pair_id as int) IN ({expr_ids})"
            ),
            InputSerialization={  # éåœ§ç¸®ãªã®ã§ CompressionType ã¯æŒ‡å®šã—ãªã„
                "JSON": {"Type": "LINES"}
            },
            OutputSerialization={"JSON": {}},
        )

        out = []
        for event in resp["Payload"]:
            if "Records" in event:
                payload = event["Records"]["Payload"].decode("utf-8")
                for line in payload.splitlines():
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        out.append(json.loads(line))
                    except:
                        pass
        return out

    except ClientError:
        # KeyãŒç„¡ã„/Selectä¸å¯ãªã© â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        pass

    # ---- 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®å…¨ä»¶GETâ†’ãƒ­ãƒ¼ã‚«ãƒ«æŠ½å‡º ----
    try:
        body = s3_client.get_object(Bucket=DATA_BUCKET_NAME, Key=key_raw)["Body"].read().decode("utf-8")
        rows, ids_set = [], set(ids)
        for line in body.splitlines():
            if not line:
                continue
            try:
                obj = json.loads(line)
                if int(obj.get("pair_id", -1)) in ids_set:
                    rows.append(obj)
            except:
                pass
        return rows
    except Exception:
        return []


# ========================= UI =========================
st.title("ğŸ“œ ãã„ã¦ã‚®ã‚«ã‚¤ï½œè­°ä¼šè³ªç–‘AIåˆ†æ")

# åŒæ„ç”»é¢
if not st.session_state.agreed:
    st.markdown("""
    ### ã”åˆ©ç”¨ã«ã‚ãŸã£ã¦ã®ã”æ¡ˆå†…
    - ã“ã®ãƒãƒ£ãƒƒãƒˆã§ã¯ã€å±±å£å¸‚è­°ä¼šã®ä¸€èˆ¬è³ªå•ãƒ»è³ªç–‘ã®è­°äº‹éŒ²ã‚’ã‚‚ã¨ã«ã€è­°ä¼šã§ã©ã‚“ãªè­°è«–ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚  
    - ãƒãƒ£ãƒƒãƒˆå†…å®¹ã¯è¨˜éŒ²ã•ã‚Œã¾ã™ã€‚å†…å®¹ã®è¨˜éŒ²ã«åŒæ„ã•ã‚ŒãŸæ–¹ã®ã¿ã€ãƒãƒ£ãƒƒãƒˆã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚
    - **å€‹äººæƒ…å ±ï¼ˆæ°åãƒ»ä½æ‰€ãƒ»é€£çµ¡å…ˆãªã©ï¼‰ã®å…¥åŠ›ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚**  
    """)
    st.warning("ã“ã®ãƒãƒ£ãƒƒãƒˆã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®å†…å®¹ã«åŒæ„ã„ãŸã ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
    if st.button("âœ… åŒæ„ã—ã¦ãƒãƒ£ãƒƒãƒˆã‚’ã¯ã˜ã‚ã‚‹"):
        st.session_state.agreed = True
        st.rerun()
    st.stop()

# å…¥åŠ›æ¬„
st.markdown("---\n\n#### ğŸ’¬ è³ªå•ã—ã¦ã¿ã‚ˆã†")
st.text_input(
    label="",
    key="input",
    value=st.session_state.input_value,
    placeholder="ä¾‹ï¼šå­¦æ ¡ã®çµ¦é£Ÿè²»ç„¡å„ŸåŒ–ã«ã¤ã„ã¦ã©ã®ã‚ˆã†ãªè­°è«–ãŒè¡Œã‚ã‚Œã¦ã„ã¾ã™ã‹",
    on_change=lambda: st.session_state.update(send_now=True)
)

# ã‚µã‚¸ã‚§ã‚¹ãƒˆ
if not st.session_state.get("clarify_active", False):
    suggestions_master = [
        "å…¬å…±æ–½è¨­ã®çµ±å»ƒåˆã«ã¤ã„ã¦æ°—ã«ãªã‚Šã¾ã™",
        "è¡Œæ”¿ã®DXåŒ–ã¯é€²ã‚“ã§ã„ã¾ã™ã‹",
        "è¦³å…‰ãƒ»ã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰å¯¾å¿œã«ã¤ã„ã¦æ•™ãˆã¦"
    ]
    if not st.session_state.suggestions_sampled:
        st.session_state.suggestions_sampled = random.sample(suggestions_master, k=3)

    cols = st.columns(3)
    for i, s in enumerate(st.session_state.suggestions_sampled):
        if cols[i].button(f" {s}", key=f"sugg_{s}"):
            st.session_state.input_value = s
            st.session_state.query = s
            st.session_state.send_now = False
            st.session_state.is_generating = True
            st.session_state.clarify_active = False
            with st.spinner(f"â³ ã€Œ{s}ã€ã«å›ç­”ä¸­... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„"):
                results = search_s3vector_and_respond(s)
                st.session_state.last_answer = results["summary"]
                st.session_state.last_matches = results["matches"]
                st.session_state.qa_pairs = results["qa_pairs"]
                log_to_gsheet(s, results["summary"])
            st.session_state.is_generating = False
            st.rerun()

# Clarify
if st.session_state.input and not st.session_state.get("clarified", False):
    clarify_result = clarify_query(st.session_state.input)
    if clarify_result["ambiguous"] and clarify_result["rewritten_query"]:
        st.session_state.clarify_active = True
        st.info(f"ğŸ‘‡ ã‚ˆã‚Šæ­£ç¢ºãªæ¤œç´¢ã®ãŸã‚ã€Œ{clarify_result['reason']}ã€ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n\n**â†’ {clarify_result['rewritten_query']}**")

        col1, col2 = st.columns(2)
        if col1.button("ğŸ” ç½®ãæ›ãˆã¦æ¤œç´¢"):
            st.session_state.input_value = clarify_result["rewritten_query"]
            st.session_state.clarified = True
            st.session_state.clarify_active = False
            st.session_state.send_now = True
            st.rerun()
        if col2.button("ğŸ”œ å…¥åŠ›æ–‡ã®ã¾ã¾ã§æ¤œç´¢"):
            st.session_state.clarified = True
            st.session_state.clarify_active = False
            st.session_state.send_now = True
            st.rerun()
        st.stop()
    else:
        st.session_state.clarified = True

# Enteré€ä¿¡
if st.session_state.input and st.session_state.send_now:
    st.session_state.send_now = False
    st.session_state.is_generating = True
    with st.spinner(f"â³ ã€Œ{st.session_state.input}ã€ã«å›ç­”ä¸­... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„"):
        results = search_s3vector_and_respond(st.session_state.input)
        st.session_state.last_answer = results["summary"]
        st.session_state.last_matches = results["matches"]
        st.session_state.qa_pairs = results["qa_pairs"]
        log_to_gsheet(st.session_state.input, results["summary"])
    st.session_state.input_value = ""
    st.session_state.is_generating = False

# å›ç­”è¡¨ç¤º
if st.session_state.is_generating:
    st.info("â³ å›ç­”ä¸­... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„")

elif st.session_state.last_answer and st.session_state.qa_pairs:
    st.markdown("#### ğŸ’¡ è­°ä¼šè³ªå•ã®ã¾ã¨ã‚")
    st.success(st.session_state.last_answer)

    from collections import defaultdict
    groups: dict[str, list] = defaultdict(list)

    # âœ… Q/Aãƒšã‚¢ã‚’ä¼šè­°åã”ã¨ã«åˆ†é¡ï¼ˆpairã«åŸ‹ã‚è¾¼ã‚“ã  meeting_name ã‚’æœ€å„ªå…ˆï¼‰
    for p in st.session_state.qa_pairs:
        cid = (
            p.get("chunk_id")
            or (p.get("Q") and p["Q"][0].get("chunk_id"))
            or (p.get("A") and p["A"][0].get("chunk_id"))
            or ""
        )
        meeting_name = p.get("meeting_name") or (cid.split("_")[0] if cid else "ï¼ˆä¼šè­°åä¸æ˜ï¼‰")
        meeting_name = meeting_name.split("ï¼š")[-1]
        groups[meeting_name].append(p)

    # ä¼šè­°ã”ã¨ã«ã‚¿ãƒ–åŒ–ï¼ˆQ/Aä»¶æ•°ã ã‘ãƒãƒƒã‚¸è¡¨ç¤ºï¼‰
    st.markdown("#### ğŸ’¡ é–¢é€£ç™ºè¨€ã®è©³ç´°")
    meeting_names = sorted(groups.keys(), reverse=True)
    tabs = st.tabs([f"{mn}ï¼ˆ {len(groups[mn])}ï¼‰" for mn in meeting_names])

    for tab, mn in zip(tabs, meeting_names):
        with tab:
            # Q/Aãƒªã‚¹ãƒˆ
            for i, pair in enumerate(groups[mn], start=1):
                summary = (pair.get("summary") or "").strip()
                if not summary:
                    continue
                st.markdown(f"##### {i}. {summary}")
                for q in pair.get("Q", []):
                    with st.expander(f"ğŸŸ¢ã€è³ªå•ã€‘{q.get('speaker_role','')} {q.get('speaker','')}ï¼ˆ{q.get('source_file','').replace('.txt','')}ï¼‰"):
                        st.markdown(q.get("text", ""))
                for a in pair.get("A", []):
                    with st.expander(f"ğŸ”µã€ç­”å¼ã€‘{a.get('speaker_role','')} {a.get('speaker','')}ï¼ˆ{a.get('source_file','').replace('.txt','')}ï¼‰"):
                        st.markdown(a.get("text", ""))
                st.divider()

            # å…¬å¼ãƒªãƒ³ã‚¯
            st.markdown(
                """
                <div style="
                    background-color:#f5f5f5;
                    border:1px solid #ddd;
                    border-radius:6px;
                    padding:0.8em 1em;
                    margin-top:0.8em;
                    margin-bottom:0.8em;">
                    ğŸ”— å…¬å¼æƒ…å ±ã¯ã“ã¡ã‚‰ã‹ã‚‰ã”è¦§ã„ãŸã ã‘ã¾ã™<br>
                    ãƒ» <a href="https://www.city.yamaguchi.yamaguchi.dbsr.jp/index.php/" target="_blank">
                        å±±å£å¸‚è­°ä¼š è­°äº‹éŒ²ï¼ˆå…¬å¼HPï¼‰
                      </a>
                </div>
                """,
                unsafe_allow_html=True,
            )

elif st.session_state.send_now or st.session_state.input.strip() or st.session_state.query:
    st.warning("âš ï¸ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")            

# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.caption("""
âš ï¸ å›ç­”ã¯ç”ŸæˆAIã«ã‚ˆã‚‹ã‚‚ã®ã§ã‚ã‚Šã€æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚  
ğŸ™Œ æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å€‹äººã«ã‚ˆã‚Šé‹å–¶ã•ã‚Œã¦ã„ã¾ã™ã€‚ã”æ”¯æ´ã„ãŸã ã‘ã‚‹æ–¹ã¯ãœã²ã“ã¡ã‚‰ã‹ã‚‰ï¼š  
[ğŸ’› codocã§æ”¯æ´ã™ã‚‹](https://codoc.jp/sites/p8cEFlTZQA/entries/MMZnODc1dw)
""")
